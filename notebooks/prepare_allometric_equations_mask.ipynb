{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gross-jacket",
   "metadata": {},
   "source": [
    "# Make allometric equations mask\n",
    "\n",
    "Following Harris et al 2021\n",
    "([paper](https://www.nature.com/articles/s41558-020-00976-6),\n",
    "[spreadsheet](https://docs.google.com/spreadsheets/d/1Hb67l3xYCfgxKu9TnpbEfY6iQo4ISNEvQewpmYvH9yQ/edit#gid=1620488341)),\n",
    "and Farina et al\n",
    "([paper](https://docs.google.com/document/d/1qoIoYBghr7FfqZlcT8h5BGMww_Obtnrw/edit)),\n",
    "we want to use the following datasets to determine which allometric equations to\n",
    "use:\n",
    "\n",
    "- Ecoregions2017. Dinerstein, Eric, David Olson, Anup Joshi, Carly Vynne, Neil D\n",
    "  Burgess, Eric Wikramanayake, Nathan Hahn, et al. 2017. “An Ecoregion-Based\n",
    "  Approach to Protecting Half the Terrestrial Realm.” BioScience 67 (6): 534–45.\n",
    "  https://doi.org/10.1093/biosci/bix014. Retrieved from\n",
    "  https://ecoregions2017.appspot.com/ on Mar 5th, 2021.\n",
    "\n",
    "- NLCD. Retrieved from CarbonPlan data storage on GCP.\n",
    "\n",
    "- EOSD.\n",
    "\n",
    "- IGBP. Friedl, M.A., A.H. Strahler, and J. Hodges. 2010. ISLSCP II MODIS\n",
    "  (Collection 4) IGPB Land Cover, 2000-2001. In Hall, Forrest G., G. Collatz, B.\n",
    "  Meeson, S. Los, E. Brown de Colstoun, and D. Landis (eds.). ISLSCP Initiative\n",
    "  II Collection. Data set. Available on-line [http://daac.ornl.gov/] from Oak\n",
    "  Ridge National Laboratory Distributed Active Archive Center, Oak Ridge,\n",
    "  Tennessee, U.S.A. doi:10.3334/ORNLDAAC/968. Retrieved from\n",
    "  https://daac.ornl.gov/daacdata/islscp_ii/vegetation/modis_landcover_xdeg/data/.\n",
    "  Documented in\n",
    "  https://daac.ornl.gov/daacdata/islscp_ii/vegetation/modis_landcover_xdeg/comp/1_modis_landcover_doc.pdf.\n",
    "\n",
    "In this notebook, we load in each dataset, transform everything to the target\n",
    "grid, and store the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fsspec\n",
    "import os\n",
    "import shutil\n",
    "import regionmask\n",
    "import rioxarray\n",
    "\n",
    "from itertools import product\n",
    "from zarr.errors import GroupNotFoundError\n",
    "\n",
    "from carbonplan_trace.v1.utils import save_to_zarr\n",
    "\n",
    "from gcsfs import GCSFileSystem\n",
    "\n",
    "fs = GCSFileSystem(cache_timeout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_in_xr(path):\n",
    "    mapper = fsspec.get_mapper(path)\n",
    "    try:\n",
    "        ds = xr.open_zarr(mapper, chunks=None)\n",
    "        ds.attrs[\"crs\"] = \"EPSG:4326\"\n",
    "\n",
    "        return ds\n",
    "    except GroupNotFoundError:\n",
    "        print(f\"{path} empty, skipping\")\n",
    "\n",
    "\n",
    "def convert_gdf_into_tiles(tile_ds, gdf, value_col, value_name):\n",
    "    # get coordinates of target tile\n",
    "    lon_res = tile_ds.lon.values[1] - tile_ds.lon.values[0]\n",
    "    lon = np.arange(\n",
    "        tile_ds.lon.values[0], tile_ds.lon.values[-1] + (lon_res / 2), lon_res\n",
    "    )\n",
    "    lat_res = tile_ds.lat.values[1] - tile_ds.lat.values[0]\n",
    "    lat = np.arange(\n",
    "        tile_ds.lat.values[0], tile_ds.lat.values[-1] + (lat_res / 2), lat_res\n",
    "    )\n",
    "\n",
    "    # turn gdf into xarray\n",
    "    output_da = regionmask.mask_geopandas(\n",
    "        gdf, numbers=value_col, lon_or_obj=lon, lat=lat\n",
    "    )\n",
    "    output_da.name = value_name\n",
    "\n",
    "    return output_da\n",
    "\n",
    "\n",
    "def convert_raster_into_tiles(tile_ds, raster):\n",
    "    output = raster.rio.reproject_match(tile_ds)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-smart",
   "metadata": {},
   "source": [
    "# Find target tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target tiles\n",
    "lat_tags = [\n",
    "    \"80N\",\n",
    "    \"70N\",\n",
    "    \"60N\",\n",
    "    \"50N\",\n",
    "    \"40N\",\n",
    "    \"30N\",\n",
    "    \"20N\",\n",
    "    \"10N\",\n",
    "    \"00N\",\n",
    "    \"10S\",\n",
    "    \"20S\",\n",
    "    \"30S\",\n",
    "    \"40S\",\n",
    "    \"50S\",\n",
    "]\n",
    "lon_tags = [f\"{n:03}W\" for n in np.arange(10, 190, 10)] + [\n",
    "    f\"{n:03}E\" for n in np.arange(0, 180, 10)\n",
    "]\n",
    "\n",
    "tile_paths = []\n",
    "for lat, lon in list(product(lat_tags, lon_tags)):\n",
    "    tile_paths.append(f\"gs://carbonplan-climatetrace/v0/tiles/{lat}_{lon}.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lat_tags) * len(lon_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try reading each tile and remove tile name if empty\n",
    "empty_tiles = []\n",
    "for tp in tile_paths:\n",
    "    target_tile = get_tile_in_xr(tp)\n",
    "    if not target_tile:\n",
    "        empty_tiles.append(tp)\n",
    "\n",
    "for tp in empty_tiles:\n",
    "    tile_paths.remove(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-carbon",
   "metadata": {},
   "source": [
    "# Read in each dataset, consolidate as appropriate, then turn into an raster in the same format as target tiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-florence",
   "metadata": {},
   "source": [
    "### Ecoregions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"gs://carbonplan-scratch/trace_scratch/Ecoregions2017/Ecoregions2017.shp\"\n",
    "ecoregions = gpd.read_file(fp)\n",
    "ecoregions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tp in tile_paths:\n",
    "    # use the same filename as target tiles for output\n",
    "    fn = tp.split(\"/\")[-1]\n",
    "    output_path = f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/{fn}\"\n",
    "\n",
    "    if fs.exists(output_path):\n",
    "        print(f\"Skipping {fn}\")\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Processing {fn}\")\n",
    "        # read in the target tile\n",
    "        target_tile = get_tile_in_xr(tp)\n",
    "\n",
    "        # convert ecoregions shapefile into target tile format\n",
    "        output_da = convert_gdf_into_tiles(\n",
    "            tile_ds=target_tile,\n",
    "            gdf=ecoregions,\n",
    "            value_col=\"ECO_ID\",\n",
    "            value_name=\"ecoregion\",\n",
    "        )\n",
    "\n",
    "        # save the output\n",
    "        save_to_zarr(ds=output_da.to_dataset(), url=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a tile to double check output\n",
    "ds = get_tile_in_xr(\n",
    "    f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/50N_130W.zarr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ecoregion.isnull().sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ecoregion[::100, ::100].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-finger",
   "metadata": {},
   "source": [
    "### NLCD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd_conus = xr.open_rasterio(\n",
    "    \"gs://carbonplan-data/raw/nlcd/conus/30m/2001.tif\", parse_coordinates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd_conus[::100, ::100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the bounding box of NLCD data\n",
    "\n",
    "from pyproj import Transformer\n",
    "\n",
    "transformer = Transformer.from_crs(nlcd_conus.crs, \"EPSG:4326\")\n",
    "\n",
    "lat, lon = transformer.transform(nlcd_conus.x.values[0], nlcd_conus.y.values[0])\n",
    "lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = transformer.transform(\n",
    "    nlcd_conus.x.values[-1], nlcd_conus.y.values[-1]\n",
    ")\n",
    "lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "lons_of_interest = [\"130W\", \"120W\", \"110W\", \"100W\", \"090W\", \"080W\"]\n",
    "lats_of_interest = [\"50N\", \"40N\", \"30N\"]\n",
    "\n",
    "for lat, lon in list(product(lats_of_interest, lons_of_interest)):\n",
    "    # use the same filename as target tiles for output\n",
    "    fn = f\"{lat}_{lon}.zarr\"\n",
    "    #     output_path = f'gs://carbonplan-scratch/trace_scratch/nlcd_cache/{fn}'\n",
    "    output_path = f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/{fn}\"\n",
    "\n",
    "    if not fs.exists(output_path):\n",
    "        # if the target tile doesn't exist, then pass\n",
    "        print(f\"Skipping {fn}, file does not exist\")\n",
    "        pass\n",
    "\n",
    "    elif fs.exists(output_path + \"/nlcd/\"):\n",
    "        # if we have already process this tile, also pass\n",
    "        print(f\"Skipping {fn}, NLCD data already present\")\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # otherwise reproject the tile\n",
    "        print(f\"Processing {fn}\")\n",
    "        # read in the target tile\n",
    "        target_tile = get_tile_in_xr(output_path)\n",
    "        target_tile = target_tile.rename(lon=\"x\", lat=\"y\")\n",
    "\n",
    "        # convert NLCD raster into target tile format\n",
    "        output_da = convert_raster_into_tiles(\n",
    "            tile_ds=target_tile, raster=nlcd_conus\n",
    "        )\n",
    "        output_da = output_da.drop_vars(\"spatial_ref\")\n",
    "        output_da = output_da.squeeze(dim=\"band\", drop=True)\n",
    "        output_da.attrs = {\"crs\": \"EPSG:4326\"}\n",
    "        output_da.coords[\"x\"] = target_tile.x\n",
    "        output_da.coords[\"y\"] = target_tile.y\n",
    "\n",
    "        target_tile[\"nlcd\"] = output_da\n",
    "        target_tile = target_tile.rename(x=\"lon\", y=\"lat\")\n",
    "\n",
    "        # save the output\n",
    "        save_to_zarr(\n",
    "            ds=target_tile,\n",
    "            url=output_path,\n",
    "            list_of_variables=[\"nlcd\"],\n",
    "            mode=\"a\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a tile to double check output\n",
    "ds = get_tile_in_xr(\n",
    "    f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/50N_130W.zarr\"\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.nlcd[::100, ::100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ds.nlcd.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.nlcd.isnull().sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ecoregion.isnull().sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ecoregion[::100, ::100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd_ak = xr.open_rasterio(\n",
    "    \"https://storage.googleapis.com/carbonplan-data/raw/nlcd/ak/30m/2011.tif\",\n",
    "    parse_coordinates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd_ak[::100, ::100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the bounding box of NLCD data\n",
    "\n",
    "from pyproj import Transformer\n",
    "\n",
    "transformer = Transformer.from_crs(nlcd_ak.crs, \"EPSG:4326\")\n",
    "\n",
    "lat, lon = transformer.transform(nlcd_ak.x.values[0], nlcd_ak.y.values[0])\n",
    "lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = transformer.transform(nlcd_ak.x.values[-1], nlcd_ak.y.values[-1])\n",
    "lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "lons_of_interest = [\n",
    "    \"150E\",\n",
    "    \"160E\",\n",
    "    \"170E\",\n",
    "    \"180W\",\n",
    "    \"170W\",\n",
    "    \"160W\",\n",
    "    \"150W\",\n",
    "    \"140W\",\n",
    "]\n",
    "lats_of_interest = [\"70N\", \"60N\"]\n",
    "\n",
    "for lat, lon in list(product(lats_of_interest, lons_of_interest)):\n",
    "    # use the same filename as target tiles for output\n",
    "    fn = f\"{lat}_{lon}.zarr\"\n",
    "    output_path = f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/{fn}\"\n",
    "\n",
    "    if not fs.exists(output_path):\n",
    "        # if the target tile doesn't exist, then pass\n",
    "        print(f\"Skipping {fn}, file does not exist\")\n",
    "        pass\n",
    "\n",
    "    elif fs.exists(output_path + \"/nlcd/\"):\n",
    "        # if we have already process this tile, also pass\n",
    "        print(f\"Skipping {fn}, NLCD data already present\")\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # otherwise reproject the tile\n",
    "        print(f\"Processing {fn}\")\n",
    "        # read in the target tile\n",
    "        target_tile = get_tile_in_xr(output_path)\n",
    "        target_tile = target_tile.rename(lon=\"x\", lat=\"y\")\n",
    "\n",
    "        # convert NLCD raster into target tile format\n",
    "        output_da = convert_raster_into_tiles(\n",
    "            tile_ds=target_tile, raster=nlcd_ak\n",
    "        )\n",
    "        output_da = output_da.drop_vars(\"spatial_ref\")\n",
    "        output_da = output_da.squeeze(dim=\"band\", drop=True)\n",
    "        output_da.attrs = {\"crs\": \"EPSG:4326\"}\n",
    "        output_da.coords[\"x\"] = target_tile.x\n",
    "        output_da.coords[\"y\"] = target_tile.y\n",
    "\n",
    "        target_tile[\"nlcd\"] = output_da\n",
    "        target_tile = target_tile.rename(x=\"lon\", y=\"lat\")\n",
    "\n",
    "        # save the output\n",
    "        save_to_zarr(\n",
    "            ds=target_tile,\n",
    "            url=output_path,\n",
    "            list_of_variables=[\"nlcd\"],\n",
    "            mode=\"a\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a tile to double check output\n",
    "ds = get_tile_in_xr(\n",
    "    f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/70N_140W.zarr\"\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ds.nlcd.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.nlcd[::100, ::100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ecoregion[::100, ::100].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-niagara",
   "metadata": {},
   "source": [
    "### IGBP\n",
    "\n",
    "documentations:\n",
    "https://daac.ornl.gov/daacdata/islscp_ii/vegetation/modis_landcover_xdeg/comp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = '../data/IGBP/modis_landcover_class_qd.asc'\n",
    "# # the first 6 lines are additional info not data\n",
    "# headers = 6\n",
    "# igbp = np.genfromtxt(fn, skip_header=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(fn) as f:\n",
    "#     head = [next(f) for x in range(headers)]\n",
    "# print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rasterio.transform import Affine\n",
    "\n",
    "# # use info in the headers\n",
    "# ncols = 1440\n",
    "# nrows = 720\n",
    "# xll = -180\n",
    "# yll = -90\n",
    "# res = .25\n",
    "\n",
    "# transform = Affine.translation(xll, yll+res*nrows) * Affine.scale(res, -res)\n",
    "# transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# import xarray as xr\n",
    "\n",
    "# fn = 'IGBP.tif'\n",
    "# local_target = f\"../data/{fn}\"\n",
    "# remote_target = f\"gs://carbonplan-scratch/trace_scratch/{fn}\"\n",
    "\n",
    "# os.remove(local_target)\n",
    "# with rasterio.open(\n",
    "#     local_target,\n",
    "#     'w',\n",
    "#     driver='GTiff',\n",
    "#     height=igbp.shape[0],\n",
    "#     width=igbp.shape[1],\n",
    "#     count=1,\n",
    "#     dtype=igbp.dtype,\n",
    "#     crs='+proj=latlong',\n",
    "#     transform=transform,\n",
    "# ) as dst:\n",
    "#     dst.write(igbp, 1)\n",
    "\n",
    "# dst.close()\n",
    "\n",
    "# fs.put_file(local_target, remote_target)\n",
    "# os.remove(local_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "igbp = xr.open_rasterio(\n",
    "    \"https://storage.googleapis.com/carbonplan-scratch/trace_scratch/IGBP.tif\",\n",
    "    parse_coordinates=True,\n",
    ")\n",
    "igbp = igbp.squeeze(dim=\"band\", drop=True)\n",
    "igbp = igbp.rename(x=\"lon\", y=\"lat\")\n",
    "igbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "igbp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's just not reproject since the source file is so small. we'll read the data in directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-census",
   "metadata": {},
   "source": [
    "### EOSD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-leisure",
   "metadata": {},
   "source": [
    "The following block copies the shapefiles from a ftp site.\n",
    "\n",
    "There is an alternative source for EOSD data in tif format\n",
    "http://tree.pfc.forestry.ca/ But would have needed untar unzip and to merge the\n",
    "tif files together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import ftplib\n",
    "# import urllib.request as request\n",
    "# from contextlib import closing\n",
    "\n",
    "# # source filepaths\n",
    "# ftp_server = 'ftp.maps.canada.ca'\n",
    "# path = '/pub/nrcan_rncan/vector/geobase_lcc_csc/shp_en/'\n",
    "# # dest filepaths\n",
    "# dest_path = 'carbonplan-scratch/trace_scratch/EOSD/'\n",
    "\n",
    "# ftp = ftplib.FTP(ftp_server)\n",
    "# ftp.login()\n",
    "# ftp.cwd(path)\n",
    "# folders = ftp.nlst()\n",
    "\n",
    "# for folder in folders:\n",
    "#     fnames = ftp.nlst(folder)\n",
    "#     for fn in fnames:\n",
    "#         fp = f'ftp://{ftp_server}{path}{fn}'\n",
    "#         print(fp)\n",
    "#         with closing(request.urlopen(fp)) as r:\n",
    "#             uri = dest_path + fn\n",
    "#             with fs.open(uri, 'wb') as f:\n",
    "#                 shutil.copyfileobj(r, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-making",
   "metadata": {},
   "source": [
    "The following blocks sorts the EOSD raw files according to the bounding box of\n",
    "each tile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from carbonplan_trace.v1.glas_allometric_eq import (\n",
    "    parse_bounding_lat_lon_for_tile,\n",
    ")\n",
    "from shapely import geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of tiles of interest and their respective bounding boxes\n",
    "all_tiles = [\n",
    "    p.split(\"/\")[-1].split(\".\")[0]\n",
    "    for p in fs.ls(\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/\")\n",
    "    if not p.endswith(\"/\")\n",
    "]\n",
    "\n",
    "tile_poly = []\n",
    "for tile in all_tiles:\n",
    "    min_lat, max_lat, min_lon, max_lon = parse_bounding_lat_lon_for_tile(tile)\n",
    "    tile_poly.append(\n",
    "        geometry.Polygon(\n",
    "            [\n",
    "                [min_lon, min_lat],\n",
    "                [min_lon, max_lat],\n",
    "                [max_lon, max_lat],\n",
    "                [max_lon, min_lat],\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "tile_gdf = gpd.GeoDataFrame(\n",
    "    {\"tile_name\": all_tiles, \"geometry\": tile_poly}, crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "eosd_folder = \"gs://carbonplan-scratch/trace_scratch/EOSD/\"\n",
    "eosd_subfolders = [p for p in fs.ls(eosd_folder) if not p.endswith(\"/\")]\n",
    "\n",
    "for eosd_subfolder in eosd_subfolders:\n",
    "    zip_files = fs.ls(eosd_subfolder)\n",
    "    for zip_file in zip_files:\n",
    "        fn = zip_file.split(\"/\")[-1]\n",
    "        input_file = f\"gs://{zip_file}\"\n",
    "        eosd_raw = gpd.read_file(input_file)\n",
    "        min_lon, min_lat, max_lon, max_lat = eosd_raw.total_bounds\n",
    "        eosd_poly = geometry.Polygon(\n",
    "            [\n",
    "                [min_lon, min_lat],\n",
    "                [min_lon, max_lat],\n",
    "                [max_lon, max_lat],\n",
    "                [max_lon, min_lat],\n",
    "            ]\n",
    "        )\n",
    "        # figure out which tile it belongs to\n",
    "        intersect_tiles = tile_gdf.loc[\n",
    "            tile_gdf.intersects(eosd_poly)\n",
    "        ].tile_name.values\n",
    "        for intersect_tile in intersect_tiles:\n",
    "            fs.cp(\n",
    "                f\"gs://{zip_file}\",\n",
    "                f\"gs://carbonplan-scratch/trace_scratch/EOSD_sorted/{intersect_tile}/{fn}\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = fsspec.get_mapper(\n",
    "    f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/50N_080W.zarr\"\n",
    ")\n",
    "ds = xr.open_dataset(mapper, engine=\"zarr\", cache=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-settlement",
   "metadata": {},
   "source": [
    "For each tile, concatenate everything and turn into raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-provider",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_tiles = [\n",
    "    p\n",
    "    for p in fs.ls(f\"gs://carbonplan-scratch/trace_scratch/EOSD_sorted/\")\n",
    "    if not p.endswith(\"/\")\n",
    "]\n",
    "\n",
    "for tile in all_tiles:\n",
    "    fn = tile.split(\"/\")[-1]\n",
    "    tile_path = (\n",
    "        f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/{fn}.zarr\"\n",
    "    )\n",
    "\n",
    "    if fs.exists(tile_path + \"/eosd/\"):\n",
    "        # if we have already process this tile, also pass\n",
    "        print(f\"Skipping {fn}, EOSD data already present\")\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        print(f\"Processing {fn}\")\n",
    "        zip_files = fs.ls(tile)\n",
    "        eosd = []\n",
    "        for zf in zip_files:\n",
    "            print(f\"    reading {zf}\")\n",
    "            temp = gpd.read_file(\"gs://\" + zf)\n",
    "            print(temp.total_bounds)\n",
    "            eosd.append(temp)\n",
    "\n",
    "        print(\"concat\")\n",
    "        eosd = pd.concat(eosd, ignore_index=True)\n",
    "\n",
    "        # read in the target tile\n",
    "        target_tile = get_tile_in_xr(tile_path)\n",
    "\n",
    "        eosd = eosd[[\"COVTYPE\", \"geometry\"]]\n",
    "        eosd = eosd.sort_values(by=\"COVTYPE\").reset_index(drop=True)\n",
    "\n",
    "        print(\"convert\")\n",
    "        # convert ecoregions shapefile into target tile format\n",
    "        eosd_index_a = (\n",
    "            convert_gdf_into_tiles(\n",
    "                tile_ds=target_tile.isel(\n",
    "                    lat=slice(0, 20000), lon=slice(0, 20000)\n",
    "                ),\n",
    "                gdf=eosd,\n",
    "                value_col=None,\n",
    "                value_name=\"eosd_index\",\n",
    "            )\n",
    "            .chunk({\"lat\": 625, \"lon\": 1250})\n",
    "            .to_dataset()\n",
    "        )\n",
    "\n",
    "        eosd_index_b = (\n",
    "            convert_gdf_into_tiles(\n",
    "                tile_ds=target_tile.isel(\n",
    "                    lat=slice(20000, 40000), lon=slice(0, 20000)\n",
    "                ),\n",
    "                gdf=eosd,\n",
    "                value_col=None,\n",
    "                value_name=\"eosd_index\",\n",
    "            )\n",
    "            .chunk({\"lat\": 625, \"lon\": 1250})\n",
    "            .to_dataset()\n",
    "        )\n",
    "\n",
    "        eosd_index_c = (\n",
    "            convert_gdf_into_tiles(\n",
    "                tile_ds=target_tile.isel(\n",
    "                    lat=slice(0, 20000), lon=slice(20000, 40000)\n",
    "                ),\n",
    "                gdf=eosd,\n",
    "                value_col=None,\n",
    "                value_name=\"eosd_index\",\n",
    "            )\n",
    "            .chunk({\"lat\": 625, \"lon\": 1250})\n",
    "            .to_dataset()\n",
    "        )\n",
    "\n",
    "        eosd_index_d = (\n",
    "            convert_gdf_into_tiles(\n",
    "                tile_ds=target_tile.isel(\n",
    "                    lat=slice(20000, 40000), lon=slice(20000, 40000)\n",
    "                ),\n",
    "                gdf=eosd,\n",
    "                value_col=None,\n",
    "                value_name=\"eosd_index\",\n",
    "            )\n",
    "            .chunk({\"lat\": 625, \"lon\": 1250})\n",
    "            .to_dataset()\n",
    "        )\n",
    "\n",
    "        eosd_index = xr.combine_by_coords(\n",
    "            [eosd_index_a, eosd_index_b, eosd_index_c, eosd_index_d]\n",
    "        )[\"eosd_index\"]\n",
    "\n",
    "        print(\"nulls in total dataset\", eosd_index.isnull().sum().values)\n",
    "\n",
    "        print(\"get output dataset\")\n",
    "        eosd_cov = xr.DataArray(\n",
    "            np.nan,\n",
    "            dims=[\"lat\", \"lon\"],\n",
    "            coords=[target_tile.coords[\"lat\"], target_tile.coords[\"lon\"]],\n",
    "        ).chunk({\"lat\": 625, \"lon\": 1250})\n",
    "\n",
    "        print(\"assigning covers\")\n",
    "        covers = eosd.COVTYPE.unique()\n",
    "        for c in covers:\n",
    "            min_ind = np.where(eosd.COVTYPE == c)[0].min()\n",
    "            max_ind = np.where(eosd.COVTYPE == c)[0].max()\n",
    "            eosd_cov = xr.where(\n",
    "                ((eosd_index >= min_ind) & (eosd_index <= max_ind)),\n",
    "                x=c,\n",
    "                y=eosd_cov,\n",
    "            )\n",
    "\n",
    "        print(\"put to output ds\")\n",
    "        target_tile[\"eosd\"] = eosd_cov\n",
    "\n",
    "        print(\"saving\")\n",
    "        # save the output\n",
    "        save_to_zarr(\n",
    "            ds=target_tile, url=tile_path, list_of_variables=[\"eosd\"], mode=\"a\"\n",
    "        )\n",
    "\n",
    "        del eosd_index\n",
    "        del eosd_index_a\n",
    "        del eosd_index_b\n",
    "        del eosd_index_c\n",
    "        del eosd_index_d\n",
    "        del eosd_cov\n",
    "        del target_tile\n",
    "        del eosd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = fsspec.get_mapper(\n",
    "    f\"gs://carbonplan-scratch/trace_scratch/ecoregions_mask/70N_100W.zarr\"\n",
    ")\n",
    "ds = xr.open_zarr(mapper)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ecoregion.isnull().sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ecoregion[::100, ::100].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.eosd.isnull().sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.eosd[::100, ::100].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
