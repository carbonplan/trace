{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from carbonplan_trace.v1.glas_preprocess import preprocess\n",
    "import carbonplan_trace.v1.glas_allometric_eq as allo\n",
    "import carbonplan_trace.v1.utils as utils\n",
    "from carbonplan_trace.v1.glas_height_metrics import get_all_height_metrics\n",
    "\n",
    "\n",
    "from gcsfs import GCSFileSystem\n",
    "\n",
    "fs = GCSFileSystem(cache_timeout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_list_of_mask_tiles(include=\"\"):\n",
    "    \"\"\"\n",
    "    Ecoregions mask is stored in 10 degree tiles, grab the filepaths\n",
    "    \"\"\"\n",
    "    fs = GCSFileSystem(cache_timeout=0)\n",
    "    mask_folder = \"gs://carbonplan-climatetrace/intermediates/ecoregions_mask/\"\n",
    "    # fs.ls includes the parent folder itself, skip that link\n",
    "    mask_paths = [\n",
    "        tp\n",
    "        for tp in fs.ls(mask_folder)\n",
    "        if not tp.endswith(\"/\") and include in tp\n",
    "    ]\n",
    "\n",
    "    all_lat_lon_tags = [\n",
    "        utils.get_lat_lon_tags_from_tile_path(tp) for tp in mask_paths\n",
    "    ]\n",
    "\n",
    "    lat_lon_tags = []\n",
    "    for lat, lon in all_lat_lon_tags:\n",
    "        output_path = f\"gs://carbonplan-climatetrace/intermediates/preprocessed_lidar/{lat}_{lon}.zarr/.zmetadata\"\n",
    "        if not fs.exists(output_path):\n",
    "            lat_lon_tags.append((lat, lon))\n",
    "\n",
    "    return lat_lon_tags\n",
    "\n",
    "\n",
    "lat_lon_tags = get_list_of_mask_tiles()\n",
    "# this should be in the order of min_lat, max_lat, min_lon, max_lon\n",
    "bounding_boxes = [\n",
    "    utils.parse_bounding_box_from_lat_lon_tags(lat, lon)\n",
    "    for lat, lon in lat_lon_tags\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=1, threads_per_worker=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from dask_gateway import Gateway\n",
    "\n",
    "# gateway = Gateway()\n",
    "# options = gateway.cluster_options()\n",
    "# options.worker_cores = 4\n",
    "# options.worker_memory = 120\n",
    "# cluster = gateway.new_cluster(cluster_options=options)\n",
    "# cluster.adapt(minimum=1, maximum=10)\n",
    "# cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = cluster.get_client()\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import PipInstall\n",
    "# plugin = PipInstall(packages=[\"git+https://github.com/carbonplan/trace.git@debug_biomass#egg=carbonplan_trace\"],\n",
    "#                     pip_options=[\"-e\"])\n",
    "# client.register_worker_plugin(plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def process_one_tile(bounding_box, skip_existing):\n",
    "    min_lat, max_lat, min_lon, max_lon = bounding_box\n",
    "    lat_tag, lon_tag = utils.get_lat_lon_tags_from_bounding_box(\n",
    "        max_lat, min_lon\n",
    "    )\n",
    "    biomass_path = f\"gs://carbonplan-climatetrace/intermediates/biomass/{lat_tag}_{lon_tag}.zarr\"\n",
    "    preprocessed_path = f\"gs://carbonplan-climatetrace/intermediates/preprocessed_lidar/{lat_tag}_{lon_tag}.zarr\"\n",
    "\n",
    "    with dask.config.set(scheduler=\"single-threaded\"):\n",
    "        if skip_existing and fs.exists(biomass_path + \"/MeanH\"):\n",
    "            return (\"skipped\", biomass_path)\n",
    "\n",
    "        if fs.exists(preprocessed_path + \"/.zmetadata\"):\n",
    "            preprocessed = (\n",
    "                open_zarr_file(preprocessed_path)\n",
    "                .stack(unique_index=(\"record_index\", \"shot_number\"))\n",
    "                .dropna(dim=\"unique_index\", subset=[\"lat\"])\n",
    "            )\n",
    "        else:\n",
    "            # read in data, this step takes about 5 mins\n",
    "            data01 = utils.open_glah01_data()\n",
    "            data14 = utils.open_glah14_data()\n",
    "\n",
    "            # subset data to the bounding box\n",
    "            sub14 = utils.subset_data_for_bounding_box(\n",
    "                data14, min_lat, max_lat, min_lon, max_lon\n",
    "            )\n",
    "            sub01 = data01.where(\n",
    "                data01.record_index.isin(sub14.record_index), drop=True\n",
    "            )\n",
    "            combined = sub14.merge(sub01, join=\"inner\")\n",
    "\n",
    "            if len(combined.record_index) == 0:\n",
    "                return (\"no data\", biomass_path)\n",
    "\n",
    "            # preprocess data and persist\n",
    "            preprocessed = preprocess(\n",
    "                combined, min_lat, max_lat, min_lon, max_lon\n",
    "            ).compute()\n",
    "            del combined, sub14, sub01\n",
    "\n",
    "            preprocessed[\"datetime\"] = preprocessed.datetime.astype(\n",
    "                \"datetime64[ns]\"\n",
    "            )\n",
    "            utils.save_to_zarr(\n",
    "                ds=preprocessed.unstack(\"unique_index\").chunk(\n",
    "                    {\"record_index\": 10000, \"shot_number\": 40}\n",
    "                ),\n",
    "                url=preprocessed_path,\n",
    "                mode=\"w\",\n",
    "            )\n",
    "\n",
    "        # calculate biomass\n",
    "        with_biomass = allo.apply_allometric_equation(\n",
    "            preprocessed, min_lat, max_lat, min_lon, max_lon\n",
    "        )\n",
    "\n",
    "        # saving output\n",
    "        height_metrics = [\n",
    "            \"VH\",\n",
    "            \"h25_Neigh\",\n",
    "            \"h50_Neigh\",\n",
    "            \"h75_Neigh\",\n",
    "            \"h90_Neigh\",\n",
    "            \"QMCH\",\n",
    "            \"MeanH\",\n",
    "            \"f_slope\",\n",
    "            \"senergy\",\n",
    "        ]\n",
    "        with_biomass = get_all_height_metrics(\n",
    "            with_biomass, height_metrics\n",
    "        ).compute()\n",
    "        variables = [\n",
    "            \"lat\",\n",
    "            \"lon\",\n",
    "            \"time\",\n",
    "            \"biomass\",\n",
    "            \"allometric_eq\",\n",
    "            \"glas_elev\",\n",
    "            \"ecoregion\",\n",
    "            \"eosd\",\n",
    "            \"nlcd\",\n",
    "            \"igbp\",\n",
    "            \"treecover2000_mean\",\n",
    "            \"burned\",\n",
    "        ]\n",
    "        utils.save_to_zarr(\n",
    "            ds=with_biomass.unstack(\"unique_index\").chunk(\n",
    "                {\"record_index\": 10000, \"shot_number\": 40}\n",
    "            ),\n",
    "            url=biomass_path,\n",
    "            list_of_variables=variables + height_metrics,\n",
    "            mode=\"w\",\n",
    "        )\n",
    "\n",
    "        return (\"processed\", biomass_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_existing = True\n",
    "\n",
    "tasks = []\n",
    "for bounding_box in bounding_boxes:\n",
    "    tasks.append(process_one_tile(bounding_box, skip_existing))\n",
    "results = dask.compute(tasks, retries=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapper = fsspec.get_mapper(\n",
    "    f\"gs://carbonplan-climatetrace/intermediates/biomass/60N_120W.zarr\"\n",
    ")\n",
    "check = xr.open_zarr(mapper)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.0 - check.biomass.isnull().mean().values) * (\n",
    "    check.dims[\"record_index\"] * check.dims[\"shot_number\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# import pandas as pd\n",
    "\n",
    "# data_dir = \"/home/jovyan/data/glas/example/\"\n",
    "# f01 = h5py.File(data_dir + 'GLAH01_033_2107_003_0241_4_02_0001.H5', \"r\")\n",
    "# table1 = f01[\"ANCILLARY_DATA\"].attrs['volt_table_1']\n",
    "# volt_table = pd.DataFrame(\n",
    "#     {\n",
    "#         'ind': np.arange(len(table1)),\n",
    "#         'volt_value': table1\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# volt_table.to_csv('/home/jovyan/trace/data/volt_to_digital_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shot(record):\n",
    "    cut = 250\n",
    "    bins = record.rec_wf_sample_dist.values[:-cut]\n",
    "    plt.figure(figsize=(6, 10))\n",
    "    #     plt.scatter(record.rec_wf.values[:-cut], bins, s=5, label=\"Raw\")  # raw wf\n",
    "    plt.plot(record.rec_wf.values[:-cut], bins, \"b\", label=\"Raw\")\n",
    "    # plot various variables found in GLAH14\n",
    "    plt.plot(\n",
    "        [-0.05, 0.5],\n",
    "        np.array([record.sig_begin_dist, record.sig_begin_dist]),\n",
    "        \"r--\",\n",
    "        label=\"Signal Beginning\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        [-0.05, 0.5],\n",
    "        np.array([record.sig_end_dist, record.sig_end_dist]),\n",
    "        \"g--\",\n",
    "        label=\"Signal End\",\n",
    "    )\n",
    "\n",
    "    # plot noise mean and std from GLAH01\n",
    "    plt.plot(\n",
    "        [record.noise_mean, record.noise_mean],\n",
    "        [bins.min(), bins.max()],\n",
    "        \"0.5\",\n",
    "        label=\"Noise Mean\",\n",
    "    )\n",
    "    n_sig = 3.5\n",
    "    noise_threshold = record.noise_mean + n_sig * record.noise_sd\n",
    "    plt.plot(\n",
    "        [noise_threshold, noise_threshold],\n",
    "        [bins.min(), bins.max()],\n",
    "        color=\"0.5\",\n",
    "        linestyle=\"dashed\",\n",
    "        label=\"Noise Threshold\",\n",
    "    )\n",
    "\n",
    "    # plot filtered wf\n",
    "    plt.plot(\n",
    "        record.processed_wf.values[:-cut] + record.noise_mean.values,\n",
    "        bins,\n",
    "        \"k-\",\n",
    "        label=\"Filtered Waveform\",\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        record.gaussian_amp,\n",
    "        record.gaussian_fit_dist,\n",
    "        s=20,\n",
    "        c=\"orange\",\n",
    "        label=\"Gaussian fits\",\n",
    "    )\n",
    "    #     # plot percentile heights\n",
    "    #     plt.plot(\n",
    "    #         [-0.05, 0.5],\n",
    "    #         [record[\"10th_distance\"], record[\"10th_distance\"]],\n",
    "    #         \"b--\",\n",
    "    #         label=\"10th Percentile\",\n",
    "    #     )\n",
    "    #     plt.plot([-0.05, 0.5], [record.meanH_dist, record.meanH_dist], \"c--\", label=\"Mean H\")\n",
    "    #     plt.plot(\n",
    "    #         [-0.05, 0.5],\n",
    "    #         [record[\"90th_distance\"], record[\"90th_distance\"]],\n",
    "    #         \"m--\",\n",
    "    #         label=\"90th Percentile\",\n",
    "    #     )\n",
    "    #     plt.plot(\n",
    "    #         [-0.05, 0.5],\n",
    "    #         [record.ground_peak_dist, record.ground_peak_dist],\n",
    "    #         \"y--\",\n",
    "    #         label=\"Ground Peak\",\n",
    "    #     )\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"lidar return (volt)\")\n",
    "    plt.ylabel(\"distance from satelite (m)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.where((p.num_gaussian_peaks > 2) & p.mask)\n",
    "\n",
    "for i in range(10):\n",
    "    ind = random.randint(0, len(pos[0]))\n",
    "    r = p.isel(record_index=pos[0][ind], shot_number=pos[1][ind])\n",
    "    plot_shot(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
