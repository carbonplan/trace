{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b7732a-58e1-439b-b6aa-046fb18ac615",
   "metadata": {},
   "source": [
    "## Post processing of aboveground biomass dataset\n",
    "\n",
    "### Input\n",
    "\n",
    "Random forest model prediction results from inference.ipynb. These are parquet\n",
    "files (1 for each landsat scene x year) with columns x, y, biomass. x, y are in\n",
    "lat/lon coordinates, and biomass is in unit of Mg biomass / ha and only accounts\n",
    "for aboveground, live, woody biomass.\n",
    "\n",
    "### Processes\n",
    "\n",
    "For each 10x10 degree tile in our template\n",
    "\n",
    "1. merge and mosaic all landsat scenes within a 10x10 degree tile for all years\n",
    "   available and store the data in zarr format\n",
    "2. fill gaps within the biomass dataset by xarray interpolate_na with linear\n",
    "   method (first through dim time, then through dim x, then dim y)\n",
    "3. mask with MODIS MCD12Q1 land cover dataset to only select the forest pixels\n",
    "4. calculate belowground biomass and deadwood and litter\n",
    "\n",
    "### To do\n",
    "\n",
    "1. take diff between years to calculate biomass change biomass_change = t0 - t1\n",
    "   sinks = clip max=0 emissions = clip min=0\n",
    "\n",
    "2. co-locate with fire only on emissions\n",
    "\n",
    "3. use emission factor to calculate fire related emissions line 44 on\n",
    "   https://docs.google.com/spreadsheets/d/11CCsl1rsAlC2y9Ilfch4jSN6tFTHspMAqfzuavh_yUI/edit#gid=0\n",
    "4. calculate non fire related emissions\n",
    "\n",
    "- still need to convert from biomass to carbon - .467 \\* 3.67 (maybe use\n",
    "  different numbers depending on whether belowground or aboveground)\n",
    "\n",
    "5. convert to mass and roll up by country\n",
    "6. test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbce1e4-4cb9-452b-b683-d26f3b0f8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyproj import CRS\n",
    "import boto3\n",
    "from rasterio.session import AWSSession\n",
    "from s3fs import S3FileSystem\n",
    "aws_session = AWSSession(boto3.Session(),#profile_name='default'), \n",
    "                         requester_pays=True)\n",
    "fs = S3FileSystem(requester_pays=True)\n",
    "import xgboost as xgb\n",
    "\n",
    "from osgeo.gdal import VSICurlClearCache\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import os\n",
    "import fsspec\n",
    "\n",
    "import rioxarray # for the extension to load\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from dask_gateway import Gateway\n",
    "from carbonplan_trace.v1.landsat_preprocess import access_credentials, test_credentials\n",
    "from carbonplan_trace.v1.inference import predict, predict_delayed \n",
    "from carbonplan_trace.v1 import utils, postprocess\n",
    "from carbonplan_trace.tiles import tiles\n",
    "\n",
    "from prefect import task, Flow, Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e439a-4b13-40b0-b7a6-ed0eaf812057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from carbonplan_trace import version\n",
    "\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075df2af-bfda-43fe-859c-d09d570a5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind_of_cluster = \"local\"\n",
    "# kind_of_cluster = \"remote\"\n",
    "# if kind_of_cluster == \"local\":\n",
    "#     # spin up local cluster. must be on big enough machine\n",
    "#     from dask.distributed import Client\n",
    "\n",
    "#     client = Client(\n",
    "#         n_workers=4,\n",
    "#         threads_per_worker=8,\n",
    "#     )\n",
    "#     client\n",
    "# else:\n",
    "#     gateway = Gateway()\n",
    "#     options = gateway.cluster_options()\n",
    "#     options.environment = {\n",
    "#         \"AWS_REQUEST_PAYER\": \"requester\",\n",
    "#         \"AWS_REGION_NAME\": \"us-west-2\",\n",
    "#     }\n",
    "#     options.worker_cores = 1\n",
    "#     options.worker_memory = 200\n",
    "\n",
    "#     options.image = \"carbonplan/trace-python-notebook:latest\"\n",
    "#     cluster = gateway.new_cluster(cluster_options=options)\n",
    "#     cluster.scale(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c210a-4d04-4c21-a0a8-c14ea9d250ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ffccec-fa70-4ca3-89e8-79efb80eb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de448c7-7840-4d72-b7f8-de452b6f2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find existing output and skip those, something like this\n",
    "\n",
    "# processed_scenes = []\n",
    "# for year in np.arange(2015, 2021):\n",
    "#     processed_scenes.extend(\n",
    "#         fs.ls(f\"{bucket}/inference/rf/{year}\", recursive=True)\n",
    "#     )\n",
    "\n",
    "# processed_scenes = [scene[-19:-8] for scene in processed_scenes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9925399-a68a-4915-9504-ddc5d2999308",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_mapper = fsspec.get_mapper(\n",
    "    f\"s3://carbonplan-climatetrace/junk/text.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980eeed-6f7b-4fad-a51e-bbfc8b98ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fsspec.open(\"s3://carbonplan-climatetrace/junk/text.txt\", mode=\"w\") as f:\n",
    "    f.write(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900c8ab-f05e-47f7-95f9-f6eb015f69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "# define starting and ending years (will want to go back to 2014 but that might not be ready right now)\n",
    "year0, year1 = 2015, 2021\n",
    "# define the size of subtile you want to work in (2 degrees recommended)\n",
    "tile_degree_size = 2\n",
    "# if you want to write the metadata for the zarr store\n",
    "write_tile_metadata = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f49be9-788c-428c-8f93-afa50827417b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tile in tiles[3:4]:\n",
    "    #     if tile not in already_processed:\n",
    "    lat_tag, lon_tag = utils.get_lat_lon_tags_from_tile_path(tile)\n",
    "    lat_lon_box = utils.parse_bounding_box_from_lat_lon_tags(lat_tag, lon_tag)\n",
    "    # find the lat_lon_box for that tile\n",
    "    min_lat, max_lat, min_lon, max_lon = lat_lon_box\n",
    "\n",
    "    # initialize empty dataset. only need to do this once, and not if the tile has already been processed\n",
    "    data_mapper = postprocess.initialize_empty_dataset(\n",
    "        lat_tag, lon_tag, year0, year1, write_tile_metadata=write_tile_metadata\n",
    "    )\n",
    "    # now we'll split up each of those tiles into smaller subtiles of length `tile_degree_size`\n",
    "    # and run through those. In this case since we've specified 2, we'll have 25 in each box\n",
    "    for lat_increment in np.arange(0, 10, tile_degree_size)[0:1]:\n",
    "        for lon_increment in np.arange(0, 10, tile_degree_size)[0:1]:\n",
    "            postprocess.postprocess_subtile(\n",
    "                min_lat,\n",
    "                min_lon,\n",
    "                lat_increment,\n",
    "                lon_increment,\n",
    "                year0,\n",
    "                year1,\n",
    "                tile_degree_size,\n",
    "                data_mapper,\n",
    "            )\n",
    "\n",
    "#         tasks.append(client.compute(postprocess_delayed(subtile_ul_lat, subtile_ul_lon, year0, year1, tile_degree_size, mapper)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
