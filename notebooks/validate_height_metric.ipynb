{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fsspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from carbonplan.data import cat\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib\n",
    "from carbonplan_data import utils\n",
    "from matplotlib import cm\n",
    "\n",
    "from carbonplan_trace.v1 import utils as trace_utils\n",
    "import os\n",
    "from carbonplan_trace.v0.data import cat as trace_cat\n",
    "from carbonplan_trace.v1 import glas_height_metrics as ht\n",
    "\n",
    "matplotlib.rc('font', family='sans-serif') \n",
    "matplotlib.rc('font', serif='Helvetica Neue') \n",
    "matplotlib.rc('text', usetex='false') \n",
    "matplotlib.rcParams.update({'font.size': 14, \"svg.fonttype\": \"none\"})\n",
    "\n",
    "# import altair as alt\n",
    "# alt.data_transformers.disable_max_rows()\n",
    "# alt.themes.enable(\"carbonplan_light\")\n",
    "\n",
    "from gcsfs import GCSFileSystem\n",
    "fs = GCSFileSystem(cache_timeout=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-phone",
   "metadata": {},
   "source": [
    "# Open data\n",
    "\n",
    "- from this study\n",
    "- from Lidar validation data sets (Margolis et al 2015 and Neigh et al 2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_study_data(tiles=None, min_lat=-90, max_lat=90, min_lon=-180, max_lon=180):\n",
    "    folder = \"gs://carbonplan-climatetrace/intermediates/preprocessed_lidar/\"\n",
    "    if not tiles:\n",
    "        tiles = [\n",
    "            os.path.splitext(os.path.split(path)[-1])[0]\n",
    "            for path in fs.ls(folder)\n",
    "            if not path.endswith(\"/\")\n",
    "        ]\n",
    "    uris = [f\"{folder}{tile}.zarr\" for tile in tiles]\n",
    "    ds_list = []\n",
    "    for uri in uris:\n",
    "        try:\n",
    "            mapper = fsspec.get_mapper(uri)\n",
    "            ds = xr.open_zarr(mapper, consolidated=True)\n",
    "            ds = ds.stack(unique_index=(\"record_index\", \"shot_number\"))\n",
    "            ds = ds.dropna(dim=\"unique_index\", how=\"any\", subset=[\"lat\", \"lon\"])\n",
    "            #             ds = ds.drop_vars('spatial_ref')\n",
    "            ds.attrs[\"crs\"] = \"EPSG:4326\"\n",
    "            ds = trace_utils.subset_data_for_bounding_box(ds, min_lat, max_lat, min_lon, max_lon)\n",
    "            ds_list.append(ds)\n",
    "        except KeyError:\n",
    "            print(f\"did not find {uri}\")\n",
    "\n",
    "    ds = xr.concat(ds_list, dim=\"unique_index\", data_vars=\"minimal\").chunk({\"unique_index\": 2000})\n",
    "    for k in ds:\n",
    "        _ = ds[k].encoding.pop(\"chunks\", None)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rename_dict = {\n",
    "    \"Glas record index\": \"record_index\",\n",
    "    \"rec_ndx\": \"record_index\",\n",
    "    \"Shotn\": \"shot_number\",\n",
    "    \"shotn\": \"shot_number\",\n",
    "    \"lngtd\": \"lon\",\n",
    "    \"h14\": \"VH\",\n",
    "    \"fslope\": \"f_slope\",\n",
    "    \"Senergy\": \"senergy\",\n",
    "    \"h25\": \"h25_Neigh\",\n",
    "    \"h50\": \"h50_Neigh\",\n",
    "    \"h75\": \"h75_Neigh\",\n",
    "    \"h90\": \"h90_Neigh\",\n",
    "    \"glas_biom_str\": \"biomass\",\n",
    "}\n",
    "\n",
    "\n",
    "def convert_df_to_xr(df):\n",
    "    df[\"unique_index\"] = (\n",
    "        df.record_index.astype(str).str.zfill(9) + \"_\" + df.shot_number.astype(str).str.zfill(2)\n",
    "    )\n",
    "    df.set_index([\"record_index\", \"shot_number\"], inplace=True)\n",
    "\n",
    "    ds = {}\n",
    "    for c in df.columns:\n",
    "        ds[c] = xr.DataArray(\n",
    "            df[c].values,\n",
    "            dims=[\"unique_index\"],\n",
    "            coords={\"unique_index\": df.unique_index.values},\n",
    "        )\n",
    "    ds = xr.Dataset(ds)\n",
    "    ds.coords[\"unique_index\"] = df.index\n",
    "    return ds\n",
    "\n",
    "\n",
    "def open_margolis_data(min_lat=-90, max_lat=90, min_lon=-180, max_lon=180):\n",
    "    files = [\n",
    "        \"gs://carbonplan-climatetrace/inputs/boreal_lidar_biomass/Alaska_BBB3_hg_L3c_L3f_wPALSbiom.txt\",\n",
    "        \"gs://carbonplan-climatetrace/inputs/boreal_lidar_biomass/Canada_east_BBB3_hg_L3c_L3f_wPALSbiom.txt\",\n",
    "        \"gs://carbonplan-climatetrace/inputs/boreal_lidar_biomass/Canada_west_BBB3_hg_L3c_L3f_wPALSbiom.txt\",\n",
    "    ]\n",
    "\n",
    "    margolis = []\n",
    "    for file in files:\n",
    "        with fs.open(file) as f:\n",
    "            data = np.genfromtxt(f, skip_header=8)\n",
    "        with fs.open(file) as f:\n",
    "            lines = f.readlines()\n",
    "        headers = lines[7]\n",
    "        headers = [c for c in headers.decode(\"utf-8\").strip().split(\" \") if c != \"\"]\n",
    "        margolis.append(pd.DataFrame(data=data, columns=headers))\n",
    "    margolis = pd.concat(margolis)\n",
    "    for c in margolis:\n",
    "        if c in rename_dict:\n",
    "            margolis.rename(columns={c: rename_dict[c]}, inplace=True)\n",
    "\n",
    "    margolis = margolis.replace(-9999, np.nan).replace(99999, np.nan)\n",
    "    margolis = convert_df_to_xr(margolis)\n",
    "    #     margolis = trace_utils.subset_data_for_bounding_box(margolis, min_lat, max_lat, min_lon, max_lon)\n",
    "\n",
    "    return margolis\n",
    "\n",
    "\n",
    "def open_neigh_data(min_lat=-90, max_lat=90, min_lon=-180, max_lon=180):\n",
    "    files = [\n",
    "        \"gs://carbonplan-climatetrace/inputs/boreal_lidar_biomass/EA_east_L3c_hg.csv\",\n",
    "        \"gs://carbonplan-climatetrace/inputs/boreal_lidar_biomass/EA_east_L3f_hg.csv\",\n",
    "        \"gs://carbonplan-climatetrace/inputs/boreal_lidar_biomass/EA_west_L2a_hg.csv\",\n",
    "        \"gs://carbonplan-climatetrace/inputs/boreal_lidar_biomass/EA_west_L3a_hg.csv\",\n",
    "    ]\n",
    "\n",
    "    neigh = []\n",
    "    for file in files:\n",
    "        with fs.open(file) as f:\n",
    "            df = pd.read_csv(f)\n",
    "        neigh.append(df)\n",
    "    neigh = pd.concat(neigh)\n",
    "    for c in neigh:\n",
    "        if c in rename_dict:\n",
    "            neigh.rename(columns={c: rename_dict[c]}, inplace=True)\n",
    "\n",
    "    neigh = neigh.replace(-9999, np.nan).replace(99999, np.nan)\n",
    "    neigh = convert_df_to_xr(neigh)\n",
    "    #     neigh = trace_utils.subset_data_for_bounding_box(neigh, min_lat, max_lat, min_lon, max_lon)\n",
    "\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "margolis = open_margolis_data()\n",
    "neigh = open_neigh_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-publication",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_lat = margolis.lat.min().values\n",
    "max_lat = margolis.lat.max().values\n",
    "min_lon = margolis.lon.min().values\n",
    "max_lon = margolis.lon.max().values\n",
    "\n",
    "tiles = trace_utils.find_tiles_for_bounding_box(\n",
    "    min_lat=min_lat, max_lat=max_lat, min_lon=min_lon, max_lon=max_lon\n",
    ")\n",
    "study1 = open_study_data(tiles=tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ds(study, ref, var_name, precision=3):\n",
    "\n",
    "    variables_study = [\n",
    "        var for var in list(study.variables.keys()) if var_name.lower() in var.lower()\n",
    "    ]\n",
    "    variables_ref = [var for var in list(ref.variables.keys()) if var_name.lower() in var.lower()]\n",
    "\n",
    "    coords = [\"lat\", \"lon\"]\n",
    "\n",
    "    left = study[variables_study + coords].to_dataframe().reset_index()\n",
    "    right = ref[variables_ref + coords].to_dataframe().reset_index()\n",
    "\n",
    "    left[\"lat_round\"] = left.lat.round(precision)\n",
    "    left[\"lon_round\"] = left.lon.round(precision)\n",
    "    right[\"lat_round\"] = right.lat.round(precision)\n",
    "    right[\"lon_round\"] = right.lon.round(precision)\n",
    "\n",
    "    return pd.merge(\n",
    "        left=left,\n",
    "        right=right,\n",
    "        on=[\"lat_round\", \"lon_round\", \"shot_number\"],\n",
    "        suffixes=[\"_study\", \"_ref\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "margolis_record_index = merge_ds(\n",
    "    study=study1, ref=margolis, var_name=\"glas_elev\"\n",
    ").record_index_study.unique()\n",
    "len(margolis_record_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "study1 = study1.where(study1.record_index.isin(margolis_record_index), drop=True)\n",
    "study1.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = neigh.lat.min().values\n",
    "max_lat = neigh.lat.max().values\n",
    "min_lon = neigh.lon.min().values\n",
    "max_lon = neigh.lon.max().values\n",
    "\n",
    "tiles = trace_utils.find_tiles_for_bounding_box(\n",
    "    min_lat=min_lat, max_lat=max_lat, min_lon=min_lon, max_lon=max_lon\n",
    ")\n",
    "study2 = open_study_data(tiles=tiles)\n",
    "\n",
    "neigh_record_index = merge_ds(\n",
    "    study=study2, ref=neigh, var_name=\"glas_elev\"\n",
    ").record_index_study.unique()\n",
    "len(neigh_record_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "study2 = study2.where(study2.record_index.isin(neigh_record_index), drop=True)\n",
    "study2.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = xr.concat([study1, study2], dim=\"unique_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "margolis.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-heading",
   "metadata": {},
   "source": [
    "## plotting function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "def plot_scatter_comparison(ax, df, col_name, compared_col_name, params):\n",
    "    xmin, xmax = params[\"xmin\"], params[\"xmax\"]\n",
    "    unit = params[\"unit\"]\n",
    "\n",
    "    x = df[compared_col_name].values\n",
    "    y = df[col_name].values\n",
    "\n",
    "    ax.plot([xmin, xmax], [xmin, xmax], \"r\")\n",
    "    r2 = r2_score(x, y)\n",
    "    rmse = mean_squared_error(x, y, squared=False)\n",
    "    ax.scatter(x, y, c=\"k\", s=0.01)\n",
    "    ax.text(params[\"text_x\"], params[\"text_y1\"], f\"R squared = {round(r2, 2)}\")\n",
    "    ax.text(params[\"text_x\"], params[\"text_y2\"], f\"RMSE = {round(rmse, 2)} {unit}\")\n",
    "    if unit != \"\":\n",
    "        unit_str = f\"({unit})\"\n",
    "    else:\n",
    "        unit_str = \"\"\n",
    "    ax.set_xlabel(f\"{compared_col_name} {unit_str}\")\n",
    "    ax.set_ylabel(f\"{col_name} {unit_str}\")\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(xmin, xmax)\n",
    "    ax.set_xticks(params[\"ticks\"])\n",
    "    ax.set_yticks(params[\"ticks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-terminology",
   "metadata": {},
   "source": [
    "# Debug specific height metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-grace",
   "metadata": {},
   "source": [
    "## QMCH and MeanH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-campbell",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate QMCH in a few different ways\n",
    "def quadratic_mean_to_ground_ht(ds):\n",
    "    \"\"\"\n",
    "    Quadratic mean height of the waveform from ground peak to signal beginning (meters).\n",
    "    Ground peak defined as whichever of the two lowest peaks has greater amplitude.\n",
    "    \"\"\"\n",
    "    return ht.get_heights_from_distance(\n",
    "        ds, top_metric=\"quadratic_mean_dist\", bottom_metric=\"ground_peak_dist\"\n",
    "    )\n",
    "\n",
    "\n",
    "def quadratic_mean_to_sig_end_ht(ds):\n",
    "    \"\"\"\n",
    "    Quadratic mean height of the waveform from ground peak to signal beginning (meters).\n",
    "    Ground peak defined as whichever of the two lowest peaks has greater amplitude.\n",
    "    \"\"\"\n",
    "    return ht.get_heights_from_distance(\n",
    "        ds, top_metric=\"quadratic_mean_dist\", bottom_metric=\"sig_end_dist\"\n",
    "    )\n",
    "\n",
    "\n",
    "study[\"QMCH_adj_ground\"] = ht.quadratic_mean_to_adj_ground_ht(study)\n",
    "study[\"QMCH_ground\"] = quadratic_mean_to_ground_ht(study)\n",
    "study[\"QMCH_sig_end\"] = quadratic_mean_to_sig_end_ht(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MeanH in a few different ways\n",
    "def mean_to_ground_ht(ds):\n",
    "    \"\"\"\n",
    "    Quadratic mean height of the waveform from ground peak to signal beginning (meters).\n",
    "    Ground peak defined as whichever of the two lowest peaks has greater amplitude.\n",
    "    \"\"\"\n",
    "    return ht.get_heights_from_distance(\n",
    "        ds, top_metric=\"mean_dist\", bottom_metric=\"ground_peak_dist\"\n",
    "    )\n",
    "\n",
    "\n",
    "def mean_to_sig_end_ht(ds):\n",
    "    \"\"\"\n",
    "    Quadratic mean height of the waveform from ground peak to signal beginning (meters).\n",
    "    Ground peak defined as whichever of the two lowest peaks has greater amplitude.\n",
    "    \"\"\"\n",
    "    return ht.get_heights_from_distance(ds, top_metric=\"mean_dist\", bottom_metric=\"sig_end_dist\")\n",
    "\n",
    "\n",
    "study[\"MeanH_adj_ground\"] = ht.mean_to_adj_ground_ht(study)\n",
    "study[\"MeanH_ground\"] = mean_to_ground_ht(study)\n",
    "study[\"MeanH_sig_end\"] = mean_to_sig_end_ht(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = [var for var in list(study.variables.keys()) if \"QMCH\" in var] + [\n",
    "    var for var in list(study.variables.keys()) if \"MeanH\" in var\n",
    "]\n",
    "\n",
    "sub = study[all_vars + [\"lat\", \"lon\"]]\n",
    "sub.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"xmin\": -12,\n",
    "    \"xmax\": 42,\n",
    "    \"unit\": \"m\",\n",
    "    \"text_x\": -8,\n",
    "    \"text_y1\": 36,\n",
    "    \"text_y2\": 30,\n",
    "    \"ticks\": np.arange(-10, 42, 10),\n",
    "}\n",
    "\n",
    "for var in [\"QMCH\", \"MeanH\"]:\n",
    "\n",
    "    joined = merge_ds(study=sub, ref=margolis, var_name=var, precision=3)\n",
    "\n",
    "    plt.figure(figsize=(13, 4.5))\n",
    "    plt.suptitle(var)\n",
    "    for i, col in enumerate([f\"{var}_adj_ground\", f\"{var}_ground\", f\"{var}_sig_end\"]):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        ax = plt.gca()\n",
    "        plot_scatter_comparison(\n",
    "            ax=ax,\n",
    "            df=joined.dropna(),\n",
    "            col_name=col,\n",
    "            compared_col_name=var,\n",
    "            params=default_params,\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-powder",
   "metadata": {},
   "source": [
    "## f slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fslope in a few different ways\n",
    "\n",
    "\n",
    "def front_slope_to_surface_energy_ratio_old(ds):\n",
    "    \"\"\"\n",
    "    Front slope to surface energy ratio. We calculated fslope_WHRC as the change in amplitude per meter (volts/meter) in the outer canopy.\n",
    "    We then applied the following linear transformation in order to calculate fslope on the same scale as provided in data published by\n",
    "    Margolis et al. (2015): f_slope = 0.5744 + 19.7762 * fslope_WHRC\n",
    "    \"\"\"\n",
    "    # get the highest peak (highest in elevation = smallest distance)\n",
    "    # the fillna is necessary since argmin raises an error otherwise\n",
    "    # the filled nans will become nans again since canopy_amp at those locations are also nans\n",
    "    canopy_ind = ds.gaussian_fit_dist.fillna(1e10).argmin(dim=\"n_gaussian_peaks\").compute()\n",
    "    canopy_amp = ds.gaussian_amp.isel(n_gaussian_peaks=canopy_ind)\n",
    "    canopy_dist = ds.gaussian_fit_dist.isel(n_gaussian_peaks=canopy_ind)\n",
    "\n",
    "    # calculate amplitude at signal begin as noise mean + nsig * noise sd since this is how signal\n",
    "    # begin is defined (ie. the highest elevation where signal crosses this threshold)\n",
    "    # the value of nsig is coded based on the GLAS Algorithm Theoretical Basis Document retrieved at\n",
    "    # https://www.csr.utexas.edu/glas/pdf/WFAtbd_v5_02011Sept.pdf  (See Appendix 3, pg 99)\n",
    "    time_of_switch = datetime(2000, 1, 1, 12, 0, 0, tzinfo=timezone.utc).timestamp() + 289742400\n",
    "    # for any time before the time of switch, b_nsig = 3.5, 7.5 afterwards\n",
    "    b_nsig = xr.where(ds.time < time_of_switch, x=3.5, y=7.5)\n",
    "\n",
    "    sig_begin_amp = ds.noise_mean + b_nsig * ds.noise_sd\n",
    "\n",
    "    # calculate slope as y2-y1 / x2-x1\n",
    "    fslope_WHRC = (canopy_amp - sig_begin_amp) / (canopy_dist - ds.sig_begin_dist)\n",
    "    # min max obtained from inspecting data in Margolis et al. (2015)\n",
    "    return (0.5744 + 19.7762 * fslope_WHRC.clip(min=0)).clip(max=15)\n",
    "\n",
    "\n",
    "def get_highest_peak_ind(ds, buffer=1):\n",
    "    \"\"\"\n",
    "    Identify highest peak in smoothed waveform, adopted after Sun et al 2008.\n",
    "    buffer indicates the lowest bin that can be identified as ground peak (buffer = 3 indicates that\n",
    "    the lowest 3 bins are excluded from ground peak identification)\n",
    "    \"\"\"\n",
    "    assert buffer >= 1\n",
    "\n",
    "    # ensure that things are ordered the same way\n",
    "    all_distances = ds.rec_wf_sample_dist.transpose(\"rec_bin\", \"unique_index\")\n",
    "    wf = ds.processed_wf.transpose(\"rec_bin\", \"unique_index\")\n",
    "\n",
    "    # initialize an array of ground peak distance with the shape of record index x shot number\n",
    "    default = wf.rec_bin.shape[0] - 2\n",
    "    highest_ind = xr.DataArray(\n",
    "        default,\n",
    "        dims=[\"unique_index\"],\n",
    "        coords=[wf.coords[\"unique_index\"]],\n",
    "    )\n",
    "\n",
    "    for i in np.arange(default, buffer, -1):\n",
    "        mask = (\n",
    "            # where the current bin has waveform intensity larger then the previous bin and the next bin\n",
    "            (wf.isel(rec_bin=i) > wf.isel(rec_bin=i - 1))\n",
    "            & (wf.isel(rec_bin=i) > wf.isel(rec_bin=i + 1))\n",
    "            & (highest_ind == default)  # and this is the first peak found\n",
    "        )\n",
    "\n",
    "        # where mask = True, set the ground distance to be equal to distance of current bin i\n",
    "        # otherwise continue to use the data stored in ground distance\n",
    "        highest_ind = xr.where(mask, x=i, y=highest_ind)\n",
    "\n",
    "    return highest_ind\n",
    "\n",
    "\n",
    "def front_slope_to_surface_energy_ratio_smooth(ds):\n",
    "    \"\"\"\n",
    "    Front slope to surface energy ratio. We calculated fslope_WHRC as the change in amplitude per meter (volts/meter) in the outer canopy.\n",
    "    We then applied the following linear transformation in order to calculate fslope on the same scale as provided in data published by\n",
    "    Margolis et al. (2015): f_slope = 0.5744 + 19.7762 * fslope_WHRC\n",
    "    \"\"\"\n",
    "    highest_ind = get_highest_peak_ind(ds).compute()\n",
    "\n",
    "    canopy_amp = ds.processed_wf.isel(rec_bin=highest_ind)\n",
    "    canopy_dist = ds.rec_wf_sample_dist.isel(rec_bin=highest_ind)\n",
    "\n",
    "    # calculate amplitude at signal begin as noise mean + nsig * noise sd since this is how signal\n",
    "    # begin is defined (ie. the highest elevation where signal crosses this threshold)\n",
    "    # the value of nsig is coded based on the GLAS Algorithm Theoretical Basis Document retrieved at\n",
    "    # https://www.csr.utexas.edu/glas/pdf/WFAtbd_v5_02011Sept.pdf  (See Appendix 3, pg 99)\n",
    "    time_of_switch = datetime(2000, 1, 1, 12, 0, 0, tzinfo=timezone.utc).timestamp() + 289742400\n",
    "    # for any time before the time of switch, b_nsig = 3.5, 7.5 afterwards\n",
    "    b_nsig = xr.where(ds.time < time_of_switch, x=3.5, y=7.5)\n",
    "\n",
    "    sig_begin_amp = ds.noise_mean + b_nsig * ds.noise_sd\n",
    "\n",
    "    # calculate slope as y2-y1 / x2-x1\n",
    "    fslope_WHRC = (canopy_amp - sig_begin_amp) / (canopy_dist - ds.sig_begin_dist)\n",
    "    # min max obtained from inspecting data in Margolis et al. (2015)\n",
    "    return (0.5744 + 19.7762 * fslope_WHRC.clip(min=0)).clip(max=15)\n",
    "\n",
    "\n",
    "def front_slope_to_surface_energy_ratio_old_max(ds):\n",
    "    \"\"\"\n",
    "    Front slope to surface energy ratio. We calculated fslope_WHRC as the change in amplitude per meter (volts/meter) in the outer canopy.\n",
    "    We then applied the following linear transformation in order to calculate fslope on the same scale as provided in data published by\n",
    "    Margolis et al. (2015): f_slope = 0.5744 + 19.7762 * fslope_WHRC\n",
    "    \"\"\"\n",
    "    # get the highest peak (highest in elevation = smallest distance)\n",
    "    # the fillna is necessary since argmin raises an error otherwise\n",
    "    # the filled nans will become nans again since canopy_amp at those locations are also nans\n",
    "    canopy_ind = ds.gaussian_amp.fillna(-99).argmax(dim=\"n_gaussian_peaks\").compute()\n",
    "    canopy_amp = ds.gaussian_amp.isel(n_gaussian_peaks=canopy_ind)\n",
    "    canopy_dist = ds.gaussian_fit_dist.isel(n_gaussian_peaks=canopy_ind)\n",
    "\n",
    "    # calculate amplitude at signal begin as noise mean + nsig * noise sd since this is how signal\n",
    "    # begin is defined (ie. the highest elevation where signal crosses this threshold)\n",
    "    # the value of nsig is coded based on the GLAS Algorithm Theoretical Basis Document retrieved at\n",
    "    # https://www.csr.utexas.edu/glas/pdf/WFAtbd_v5_02011Sept.pdf  (See Appendix 3, pg 99)\n",
    "    time_of_switch = datetime(2000, 1, 1, 12, 0, 0, tzinfo=timezone.utc).timestamp() + 289742400\n",
    "    # for any time before the time of switch, b_nsig = 3.5, 7.5 afterwards\n",
    "    b_nsig = xr.where(ds.time < time_of_switch, x=3.5, y=7.5)\n",
    "\n",
    "    sig_begin_amp = ds.noise_mean + b_nsig * ds.noise_sd\n",
    "\n",
    "    # calculate slope as y2-y1 / x2-x1\n",
    "    fslope_WHRC = (canopy_amp - sig_begin_amp) / (canopy_dist - ds.sig_begin_dist)\n",
    "    # min max obtained from inspecting data in Margolis et al. (2015)\n",
    "    return (0.5744 + 19.7762 * fslope_WHRC.clip(min=0)).clip(max=15)\n",
    "\n",
    "\n",
    "def front_slope_to_surface_energy_ratio_smooth_max(ds):\n",
    "    \"\"\"\n",
    "    Front slope to surface energy ratio. We calculated fslope_WHRC as the change in amplitude per meter (volts/meter) in the outer canopy.\n",
    "    We then applied the following linear transformation in order to calculate fslope on the same scale as provided in data published by\n",
    "    Margolis et al. (2015): f_slope = 0.5744 + 19.7762 * fslope_WHRC\n",
    "    \"\"\"\n",
    "    max_ind = ds.processed_wf.fillna(-99).argmax(dim=\"rec_bin\").compute()\n",
    "    canopy_amp = ds.processed_wf.isel(rec_bin=max_ind)\n",
    "    canopy_dist = ds.rec_wf_sample_dist.isel(rec_bin=max_ind)\n",
    "\n",
    "    # calculate amplitude at signal begin as noise mean + nsig * noise sd since this is how signal\n",
    "    # begin is defined (ie. the highest elevation where signal crosses this threshold)\n",
    "    # the value of nsig is coded based on the GLAS Algorithm Theoretical Basis Document retrieved at\n",
    "    # https://www.csr.utexas.edu/glas/pdf/WFAtbd_v5_02011Sept.pdf  (See Appendix 3, pg 99)\n",
    "    time_of_switch = datetime(2000, 1, 1, 12, 0, 0, tzinfo=timezone.utc).timestamp() + 289742400\n",
    "    # for any time before the time of switch, b_nsig = 3.5, 7.5 afterwards\n",
    "    b_nsig = xr.where(ds.time < time_of_switch, x=3.5, y=7.5)\n",
    "\n",
    "    sig_begin_amp = ds.noise_mean + b_nsig * ds.noise_sd\n",
    "\n",
    "    # calculate slope as y2-y1 / x2-x1\n",
    "    fslope_WHRC = (canopy_amp - sig_begin_amp) / (canopy_dist - ds.sig_begin_dist)\n",
    "    # min max obtained from inspecting data in Margolis et al. (2015)\n",
    "    return (0.5744 + 19.7762 * fslope_WHRC.clip(min=0)).clip(max=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "study[\"f_slope_old\"] = front_slope_to_surface_energy_ratio_old(study)\n",
    "study[\"f_slope_smooth\"] = front_slope_to_surface_energy_ratio_smooth(study)\n",
    "\n",
    "study[\"f_slope_old_max\"] = front_slope_to_surface_energy_ratio_old_max(study)\n",
    "study[\"f_slope_smooth_max\"] = front_slope_to_surface_energy_ratio_smooth_max(study)\n",
    "\n",
    "all_vars = [var for var in list(study.variables.keys()) if \"f_slope\" in var]\n",
    "\n",
    "sub_fslope = study[all_vars + [\"lat\", \"lon\"]]\n",
    "sub_fslope.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_comparison(ax, df, col_name, compared_col_name, params):\n",
    "    xmin, xmax = params[\"xmin\"], params[\"xmax\"]\n",
    "    unit = params[\"unit\"]\n",
    "\n",
    "    cond = (df[col_name] >= 2.552) & (df[col_name] <= 10) & (df[compared_col_name] <= 10)\n",
    "    x = df.loc[cond, compared_col_name].values\n",
    "    y = df.loc[cond, col_name].values\n",
    "\n",
    "    ax.plot([xmin, xmax], [xmin, xmax], \"r\")\n",
    "    r2 = r2_score(x, y)\n",
    "    rmse = mean_squared_error(x, y, squared=False)\n",
    "    ax.scatter(x, y, c=\"k\", s=0.01)\n",
    "    ax.text(params[\"text_x\"], params[\"text_y1\"], f\"R squared = {round(r2, 2)}\")\n",
    "    ax.text(params[\"text_x\"], params[\"text_y2\"], f\"RMSE = {round(rmse, 2)} {unit}\")\n",
    "    if unit != \"\":\n",
    "        unit_str = f\"({unit})\"\n",
    "    else:\n",
    "        unit_str = \"\"\n",
    "    ax.set_xlabel(f\"{compared_col_name} {unit_str}\")\n",
    "    ax.set_ylabel(f\"{col_name} {unit_str}\")\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(xmin, xmax)\n",
    "    ax.set_xticks(params[\"ticks\"])\n",
    "    ax.set_yticks(params[\"ticks\"])\n",
    "\n",
    "\n",
    "var = \"f_slope\"\n",
    "joined = merge_ds(study=sub_fslope, ref=neigh, var_name=var, precision=3)\n",
    "plot_params = {\n",
    "    \"xmin\": -0.5,\n",
    "    \"xmax\": 8.5,\n",
    "    \"unit\": \"\",\n",
    "    \"text_x\": 0.3,\n",
    "    \"text_y1\": 7.5,\n",
    "    \"text_y2\": 6.5,\n",
    "    \"ticks\": np.arange(0, 8.5, 2),\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8.5, 9))\n",
    "plt.suptitle(var)\n",
    "for i, col in enumerate([\"f_slope_old\", \"f_slope_smooth\", \"f_slope_old_max\", \"f_slope_smooth_max\"]):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    ax = plt.gca()\n",
    "    plot_scatter_comparison(\n",
    "        ax=ax,\n",
    "        df=joined.dropna(),\n",
    "        col_name=col,\n",
    "        compared_col_name=var,\n",
    "        params=plot_params,\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-above",
   "metadata": {},
   "source": [
    "## senergy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_adj_ground_to_sig_end_old(ds):\n",
    "    \"\"\"\n",
    "    Waveform energy from the ground peak.  We calculated senergy_whrc as the energy of the waveform (in digital counts) from the ground peak\n",
    "    to the signal end multiplied by two. Ground peak defined as whichever of the two lowest peaks has greater amplitude. We then applied the\n",
    "    following linear transformation in order to calculate on the same scale as data published by Margolis et al. (2015)\n",
    "    senergy = -4.397006 + 0.006208 * senergy_whrc\n",
    "    \"\"\"\n",
    "    from carbonplan_trace.v1.glas_preprocess import (\n",
    "        select_valid_area,\n",
    "    )  # avoid circular import\n",
    "\n",
    "    path = \"gs://carbonplan-climatetrace/inputs/volt_table.csv\"\n",
    "    volt_table = pd.read_csv(path)\n",
    "    volt_to_digital_count = volt_table.set_index(\"volt_value\")[\"ind\"].to_dict()\n",
    "    wf_in_digital_count = xr.apply_ufunc(\n",
    "        volt_to_digital_count.__getitem__,\n",
    "        ds.rec_wf.astype(float).round(6).fillna(-0.195279),\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "    )\n",
    "\n",
    "    ds = ht.get_dist_metric_value(ds, metric=\"adj_ground_peak_dist\")\n",
    "    # the processed wf is from sig beg to sig end, select adj ground peak to sig end instead\n",
    "    ground_energy = select_valid_area(\n",
    "        bins=ds.rec_wf_sample_dist,\n",
    "        wf=wf_in_digital_count,\n",
    "        signal_begin_dist=ds.adj_ground_peak_dist,\n",
    "        signal_end_dist=ds.sig_end_dist,\n",
    "    )\n",
    "\n",
    "    # make sure dimensions matches up\n",
    "    dims = ds.processed_wf.dims\n",
    "    ground_energy = ground_energy.transpose(dims[0], dims[1])\n",
    "\n",
    "    senergy_whrc = ground_energy.sum(dim=\"rec_bin\") * 2\n",
    "\n",
    "    return -4.397006 + 0.006208 * senergy_whrc\n",
    "\n",
    "\n",
    "def energy_adj_ground_to_sig_end_smooth(ds):\n",
    "    \"\"\"\n",
    "    Waveform energy from the ground peak.  We calculated senergy_whrc as the energy of the waveform (in digital counts) from the ground peak\n",
    "    to the signal end multiplied by two. Ground peak defined as whichever of the two lowest peaks has greater amplitude. We then applied the\n",
    "    following linear transformation in order to calculate on the same scale as data published by Margolis et al. (2015)\n",
    "    senergy = -4.397006 + 0.006208 * senergy_whrc\n",
    "    \"\"\"\n",
    "    from carbonplan_trace.v1.glas_preprocess import (\n",
    "        select_valid_area,\n",
    "        smooth_wf,\n",
    "    )  # avoid circular import\n",
    "\n",
    "    path = \"gs://carbonplan-climatetrace/inputs/volt_table.csv\"\n",
    "    volt_table = pd.read_csv(path)\n",
    "    volt_to_digital_count = volt_table.set_index(\"volt_value\")[\"ind\"].to_dict()\n",
    "\n",
    "    wf_in_digital_count = xr.apply_ufunc(\n",
    "        volt_to_digital_count.__getitem__,\n",
    "        ds.rec_wf.astype(float).round(6).fillna(-0.195279),\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "    )\n",
    "\n",
    "    smoothed_digital_cnt = xr.apply_ufunc(\n",
    "        smooth_wf,\n",
    "        wf_in_digital_count,\n",
    "        ds.tx_wf.fillna(0),\n",
    "        input_core_dims=[[\"rec_bin\"], [\"tx_bin\"]],\n",
    "        output_core_dims=[[\"rec_bin\"]],\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "        dask_gufunc_kwargs={\"allow_rechunk\": 1},\n",
    "    )\n",
    "\n",
    "    ds = ht.get_dist_metric_value(ds, metric=\"adj_ground_peak_dist\")\n",
    "    # the processed wf is from sig beg to sig end, select adj ground peak to sig end instead\n",
    "    ground_energy = select_valid_area(\n",
    "        bins=ds.rec_wf_sample_dist,\n",
    "        wf=smoothed_digital_cnt,\n",
    "        signal_begin_dist=ds.adj_ground_peak_dist,\n",
    "        signal_end_dist=ds.sig_end_dist,\n",
    "    )\n",
    "\n",
    "    # make sure dimensions matches up\n",
    "    dims = ds.processed_wf.dims\n",
    "    ground_energy = ground_energy.transpose(dims[0], dims[1])\n",
    "\n",
    "    senergy_whrc = ground_energy.sum(dim=\"rec_bin\") * 2\n",
    "\n",
    "    return -4.397006 + 0.006208 * senergy_whrc\n",
    "\n",
    "\n",
    "def energy_adj_ground_to_sig_end_no_transform(ds):\n",
    "    \"\"\"\n",
    "    Waveform energy from the ground peak.  We calculated senergy_whrc as the energy of the waveform (in digital counts) from the ground peak\n",
    "    to the signal end multiplied by two. Ground peak defined as whichever of the two lowest peaks has greater amplitude. We then applied the\n",
    "    following linear transformation in order to calculate on the same scale as data published by Margolis et al. (2015)\n",
    "    senergy = -4.397006 + 0.006208 * senergy_whrc\n",
    "    \"\"\"\n",
    "    from carbonplan_trace.v1.glas_preprocess import (\n",
    "        select_valid_area,\n",
    "        smooth_wf,\n",
    "    )  # avoid circular import\n",
    "\n",
    "    ds = ht.get_dist_metric_value(ds, metric=\"adj_ground_peak_dist\")\n",
    "    # the processed wf is from sig beg to sig end, select adj ground peak to sig end instead\n",
    "    ground_energy = select_valid_area(\n",
    "        bins=ds.rec_wf_sample_dist,\n",
    "        wf=ds.processed_wf,\n",
    "        signal_begin_dist=ds.adj_ground_peak_dist,\n",
    "        signal_end_dist=ds.sig_end_dist,\n",
    "    )\n",
    "\n",
    "    # make sure dimensions matches up\n",
    "    dims = ds.processed_wf.dims\n",
    "    ground_energy = ground_energy.transpose(dims[0], dims[1])\n",
    "\n",
    "    senergy_whrc = ground_energy.sum(dim=\"rec_bin\") * 2\n",
    "\n",
    "    return senergy_whrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_ground_peak_dist(ds):\n",
    "    \"\"\"\n",
    "    the centroid position of whichever of the two lowest fitted Gaussian peaks has greater amplitude, as defined by Rosette, North, and Suarez (2008)\n",
    "    \"\"\"\n",
    "    # find the larger peak between the bottom two\n",
    "    # We have a filter where we only process records with at least 2 peaks -- fillna is needed here because argmax doesn't deal with all nans\n",
    "    loc = (\n",
    "        ds.gaussian_amp.isel(n_gaussian_peaks=slice(2))\n",
    "        .fillna(0)\n",
    "        .argmax(dim=\"n_gaussian_peaks\")\n",
    "        .compute()\n",
    "    )\n",
    "    return ds.gaussian_fit_dist.isel(n_gaussian_peaks=loc)\n",
    "\n",
    "\n",
    "def get_adj_ground_peak_dist_new(ds):\n",
    "    at_least_two_peaks = study.num_gaussian_peaks > 2\n",
    "    loc = (\n",
    "        study.gaussian_amp.isel(n_gaussian_peaks=slice(2))\n",
    "        .fillna(0)\n",
    "        .argmax(dim=\"n_gaussian_peaks\")\n",
    "        .compute()\n",
    "    )\n",
    "    loc = xr.where(at_least_two_peaks, loc, 0)\n",
    "    return ds.gaussian_fit_dist.isel(n_gaussian_peaks=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_adj_ground_to_sig_end_new_adj(ds):\n",
    "    \"\"\"\n",
    "    Waveform energy from the ground peak.  We calculated senergy_whrc as the energy of the waveform (in digital counts) from the ground peak\n",
    "    to the signal end multiplied by two. Ground peak defined as whichever of the two lowest peaks has greater amplitude. We then applied the\n",
    "    following linear transformation in order to calculate on the same scale as data published by Margolis et al. (2015)\n",
    "    senergy = -4.397006 + 0.006208 * senergy_whrc\n",
    "    \"\"\"\n",
    "    from carbonplan_trace.v1.glas_preprocess import (\n",
    "        select_valid_area,\n",
    "    )  # avoid circular import\n",
    "\n",
    "    path = \"gs://carbonplan-climatetrace/inputs/volt_table.csv\"\n",
    "    volt_table = pd.read_csv(path)\n",
    "    volt_to_digital_count = volt_table.set_index(\"volt_value\")[\"ind\"].to_dict()\n",
    "    wf_in_digital_count = xr.apply_ufunc(\n",
    "        volt_to_digital_count.__getitem__,\n",
    "        ds.rec_wf.astype(float).round(6).fillna(-0.195279),\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "    )\n",
    "\n",
    "    adj_ground_peak_dist = get_adj_ground_peak_dist_new(ds)\n",
    "    # the processed wf is from sig beg to sig end, select adj ground peak to sig end instead\n",
    "    ground_energy = select_valid_area(\n",
    "        bins=ds.rec_wf_sample_dist,\n",
    "        wf=wf_in_digital_count,\n",
    "        signal_begin_dist=adj_ground_peak_dist,\n",
    "        signal_end_dist=ds.sig_end_dist,\n",
    "    )\n",
    "\n",
    "    # make sure dimensions matches up\n",
    "    dims = ds.processed_wf.dims\n",
    "    ground_energy = ground_energy.transpose(dims[0], dims[1])\n",
    "\n",
    "    senergy_whrc = ground_energy.sum(dim=\"rec_bin\") * 2\n",
    "\n",
    "    return -4.397006 + 0.006208 * senergy_whrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study['senergy_old'] = energy_adj_ground_to_sig_end_old(study)\n",
    "# study['senergy_smooth'] = energy_adj_ground_to_sig_end_smooth(study)\n",
    "# study['senergy_no_transform'] = energy_adj_ground_to_sig_end_no_transform(study)\n",
    "\n",
    "study[\"senergy_new_adj\"] = energy_adj_ground_to_sig_end_new_adj(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = [var for var in list(study.variables.keys()) if \"senergy\" in var] + [\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "]\n",
    "all_vars\n",
    "\n",
    "sub = study[all_vars]\n",
    "sub.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_comparison(ax, df, col_name, compared_col_name, params):\n",
    "    xmin, xmax = params[\"xmin\"], params[\"xmax\"]\n",
    "    unit = params[\"unit\"]\n",
    "\n",
    "    #     cond = (df[col_name] >= 26.643) & (df[col_name] <= 150) & (df[compared_col_name] <= 150)\n",
    "    cond = [True] * len(df)\n",
    "    x = df.loc[cond, compared_col_name].values\n",
    "    y = df.loc[cond, col_name].values\n",
    "\n",
    "    ax.plot([xmin, xmax], [xmin, xmax], \"r\")\n",
    "    r2 = r2_score(x, y)\n",
    "    rmse = mean_squared_error(x, y, squared=False)\n",
    "    ax.scatter(x, y, c=\"k\", s=0.01, alpha=0.5)\n",
    "    ax.text(params[\"text_x\"], params[\"text_y1\"], f\"R squared = {round(r2, 2)}\")\n",
    "    ax.text(params[\"text_x\"], params[\"text_y2\"], f\"RMSE = {round(rmse, 2)} {unit}\")\n",
    "    if unit != \"\":\n",
    "        unit_str = f\"({unit})\"\n",
    "    else:\n",
    "        unit_str = \"\"\n",
    "    ax.set_xlabel(f\"{compared_col_name} {unit_str}\")\n",
    "    ax.set_ylabel(f\"{col_name} {unit_str}\")\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(xmin, xmax)\n",
    "    ax.set_xticks(params[\"ticks\"])\n",
    "    ax.set_yticks(params[\"ticks\"])\n",
    "\n",
    "\n",
    "var = \"senergy\"\n",
    "joined = merge_ds(study=sub, ref=margolis, var_name=var, precision=3)\n",
    "plot_params = {\n",
    "    \"xmin\": -10,\n",
    "    \"xmax\": 210,\n",
    "    \"unit\": \"\",\n",
    "    \"text_x\": 10,\n",
    "    \"text_y1\": 180,\n",
    "    \"text_y2\": 155,\n",
    "    \"ticks\": np.arange(0, 210, 50),\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(13, 9))\n",
    "plt.suptitle(var)\n",
    "for i, col in enumerate(\n",
    "    [\"senergy_old\", \"senergy_no_transform\", \"senergy_smooth\", \"senergy_new_adj\"]\n",
    "):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    ax = plt.gca()\n",
    "    plot_scatter_comparison(\n",
    "        ax=ax,\n",
    "        df=joined.dropna(),\n",
    "        col_name=col,\n",
    "        compared_col_name=var,\n",
    "        params=plot_params,\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "study[\"neigh_25_old\"] = ht.pct_25_to_adj_ground_ht(study)\n",
    "study[\"neigh_50_old\"] = ht.pct_50_to_adj_ground_ht(study)\n",
    "study[\"neigh_75_old\"] = ht.pct_75_to_adj_ground_ht(study)\n",
    "study[\"neigh_90_old\"] = ht.pct_90_to_adj_ground_ht(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_25_to_ground_ht(ds):\n",
    "    return ht.get_heights_from_distance(\n",
    "        ds, top_metric=\"pct_25_dist\", bottom_metric=\"ground_peak_dist\"\n",
    "    )\n",
    "\n",
    "\n",
    "def pct_50_to_ground_ht(ds):\n",
    "    return ht.get_heights_from_distance(\n",
    "        ds, top_metric=\"pct_50_dist\", bottom_metric=\"ground_peak_dist\"\n",
    "    )\n",
    "\n",
    "\n",
    "def pct_75_to_ground_ht(ds):\n",
    "    return ht.get_heights_from_distance(\n",
    "        ds, top_metric=\"pct_75_dist\", bottom_metric=\"ground_peak_dist\"\n",
    "    )\n",
    "\n",
    "\n",
    "def pct_90_to_ground_ht(ds):\n",
    "    return ht.get_heights_from_distance(\n",
    "        ds, top_metric=\"pct_90_dist\", bottom_metric=\"ground_peak_dist\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "study[\"neigh_25_ground\"] = pct_25_to_ground_ht(study)\n",
    "study[\"neigh_50_ground\"] = pct_50_to_ground_ht(study)\n",
    "study[\"neigh_75_ground\"] = pct_75_to_ground_ht(study)\n",
    "study[\"neigh_90_ground\"] = pct_90_to_ground_ht(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = [var for var in list(study.variables.keys()) if \"neigh\" in var] + [\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "]\n",
    "all_vars\n",
    "\n",
    "sub = study[all_vars]\n",
    "sub.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"neigh\"\n",
    "joined = merge_ds(study=sub, ref=margolis, var_name=var, precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    \"xmin\": -12,\n",
    "    \"xmax\": 42,\n",
    "    \"unit\": \"m\",\n",
    "    \"text_x\": -8,\n",
    "    \"text_y1\": 36,\n",
    "    \"text_y2\": 30,\n",
    "    \"ticks\": np.arange(-10, 42, 10),\n",
    "}\n",
    "\n",
    "for pct in [\"25\", \"50\", \"75\", \"90\"]:\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.suptitle(f\"{pct}th percentile\")\n",
    "    for i, col in enumerate([f\"neigh_{pct}_old\", f\"neigh_{pct}_ground\"]):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        ax = plt.gca()\n",
    "        plot_scatter_comparison(\n",
    "            ax=ax,\n",
    "            df=joined.dropna(),\n",
    "            col_name=col,\n",
    "            compared_col_name=f\"h{pct}_Neigh\",\n",
    "            params=default_params,\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-cleveland",
   "metadata": {},
   "source": [
    "# Review all height metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_metrics = [\n",
    "    \"VH\",\n",
    "    \"h25_Neigh\",\n",
    "    \"h50_Neigh\",\n",
    "    \"h75_Neigh\",\n",
    "    \"h90_Neigh\",\n",
    "    \"QMCH\",\n",
    "    \"MeanH\",\n",
    "    \"f_slope\",\n",
    "    \"senergy\",\n",
    "]\n",
    "study = ht.get_all_height_metrics(study, height_metrics, recalc=True).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_comparison(ax, df, col_name, params):\n",
    "    xmin, xmax = params[\"xmin\"], params[\"xmax\"]\n",
    "    unit = params[\"unit\"]\n",
    "\n",
    "    if col_name == \"f_slope\":\n",
    "        cond = (\n",
    "            df[f\"{col_name}_study\"] >= 2.552\n",
    "        )  # & (df[f'{col_name}_study'] <= 10) & (df[f'{col_name}_ref'] <= 10)\n",
    "    elif col_name == \"senergy\":\n",
    "        cond = df[f\"{col_name}_study\"] >= 26.643\n",
    "    else:\n",
    "        cond = [True] * len(df)\n",
    "\n",
    "    x = df.loc[cond, f\"{col_name}_ref\"].values\n",
    "    y = df.loc[cond, f\"{col_name}_study\"].values\n",
    "\n",
    "    ax.plot([xmin, xmax], [xmin, xmax], \"r\")\n",
    "    r2 = r2_score(x, y)\n",
    "    rmse = mean_squared_error(x, y, squared=False)\n",
    "    bias = np.mean(x - y)\n",
    "    ax.scatter(x, y, c=\"k\", s=0.01)\n",
    "    ax.text(params[\"text_x\"], params[\"text_y1\"], f\"R squared = {round(r2, 2)}\")\n",
    "    ax.text(params[\"text_x\"], params[\"text_y2\"], f\"RMSE = {round(rmse, 2)} {unit}\")\n",
    "    ax.text(params[\"text_x\"], params[\"text_y3\"], f\"bias = {round(bias, 2)} {unit}\")\n",
    "\n",
    "    if unit != \"\":\n",
    "        unit_str = f\"({unit})\"\n",
    "    else:\n",
    "        unit_str = \"\"\n",
    "    ax.set_xlabel(f\"{col_name} from reference {unit_str}\")\n",
    "    ax.set_ylabel(f\"{col_name} from this study {unit_str}\")\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(xmin, xmax)\n",
    "    ax.set_xticks(params[\"ticks\"])\n",
    "    ax.set_yticks(params[\"ticks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    \"biomass\": {\n",
    "        \"xmin\": -10,\n",
    "        \"xmax\": 360,\n",
    "        \"unit\": \"Mg/ha\",\n",
    "        \"text_x\": 10,\n",
    "        \"text_y1\": 300,\n",
    "        \"text_y2\": 280,\n",
    "        \"text_y3\": 260,\n",
    "        \"ticks\": np.arange(0, 360, 50),\n",
    "    },\n",
    "    \"VH\": {\n",
    "        \"xmin\": -2,\n",
    "        \"xmax\": 55,\n",
    "        \"unit\": \"m\",\n",
    "        \"text_x\": 2,\n",
    "        \"text_y1\": 48,\n",
    "        \"text_y2\": 42,\n",
    "        \"text_y3\": 36,\n",
    "        \"ticks\": np.arange(0, 55, 10),\n",
    "    },\n",
    "    \"f_slope\": {\n",
    "        \"xmin\": -0.5,\n",
    "        \"xmax\": 8.5,\n",
    "        \"unit\": \"\",\n",
    "        \"text_x\": 0.3,\n",
    "        \"text_y1\": 7.5,\n",
    "        \"text_y2\": 6.5,\n",
    "        \"text_y3\": 5.5,\n",
    "        \"ticks\": np.arange(0, 8.5, 2),\n",
    "    },\n",
    "    \"senergy\": {\n",
    "        \"xmin\": -10,\n",
    "        \"xmax\": 210,\n",
    "        \"unit\": \"\",\n",
    "        \"text_x\": 10,\n",
    "        \"text_y1\": 180,\n",
    "        \"text_y2\": 155,\n",
    "        \"text_y3\": 130,\n",
    "        \"ticks\": np.arange(0, 210, 50),\n",
    "    },\n",
    "}\n",
    "\n",
    "default_params = {\n",
    "    \"xmin\": -12,\n",
    "    \"xmax\": 42,\n",
    "    \"unit\": \"m\",\n",
    "    \"text_x\": -8,\n",
    "    \"text_y1\": 36,\n",
    "    \"text_y2\": 30,\n",
    "    \"text_y3\": 24,\n",
    "    \"ticks\": np.arange(-10, 42, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_compare = [\n",
    "    \"VH\",\n",
    "    \"MeanH\",\n",
    "    \"h25_Neigh\",\n",
    "    \"h50_Neigh\",\n",
    "    \"h75_Neigh\",\n",
    "    \"h90_Neigh\",\n",
    "    \"QMCH\",\n",
    "    \"f_slope\",\n",
    "    \"senergy\",\n",
    "]\n",
    "coords = [\"lat\", \"lon\"]\n",
    "all_vars = variables_to_compare + coords\n",
    "\n",
    "left = study[all_vars].to_dataframe().reset_index()\n",
    "right = margolis[all_vars].to_dataframe().reset_index()\n",
    "\n",
    "precision = 4\n",
    "\n",
    "left[\"lat_round\"] = left.lat.round(precision)\n",
    "left[\"lon_round\"] = left.lon.round(precision)\n",
    "right[\"lat_round\"] = right.lat.round(precision)\n",
    "right[\"lon_round\"] = right.lon.round(precision)\n",
    "\n",
    "joined_margolis = pd.merge(\n",
    "    left=left,\n",
    "    right=right,\n",
    "    on=[\"lat_round\", \"lon_round\", \"shot_number\"],\n",
    "    suffixes=[\"_study\", \"_ref\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 12))\n",
    "plt.suptitle(\"Comparison to Margolis et al 2015\")\n",
    "for i, var in enumerate(variables_to_compare):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    ax = plt.gca()\n",
    "    plot_scatter_comparison(\n",
    "        ax=ax,\n",
    "        df=joined_margolis.dropna(),\n",
    "        col_name=var,\n",
    "        params=plot_params.get(var, default_params),\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = study[all_vars].to_dataframe().reset_index()\n",
    "right = neigh[all_vars].to_dataframe().reset_index()\n",
    "\n",
    "precision = 4\n",
    "\n",
    "left[\"lat_round\"] = left.lat.round(precision)\n",
    "left[\"lon_round\"] = left.lon.round(precision)\n",
    "right[\"lat_round\"] = right.lat.round(precision)\n",
    "right[\"lon_round\"] = right.lon.round(precision)\n",
    "\n",
    "joined_neigh = pd.merge(\n",
    "    left=left,\n",
    "    right=right,\n",
    "    on=[\"lat_round\", \"lon_round\", \"shot_number\"],\n",
    "    suffixes=[\"_study\", \"_ref\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 12))\n",
    "plt.suptitle(\"Comparison to Neigh et al 2015\")\n",
    "for i, var in enumerate(variables_to_compare):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    ax = plt.gca()\n",
    "    plot_scatter_comparison(\n",
    "        ax=ax,\n",
    "        df=joined_neigh.dropna(),\n",
    "        col_name=var,\n",
    "        params=plot_params.get(var, default_params),\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.concat([joined_margolis, joined_neigh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 12))\n",
    "plt.suptitle(\"Comparison to all data\")\n",
    "for i, var in enumerate(variables_to_compare):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    ax = plt.gca()\n",
    "    plot_scatter_comparison(\n",
    "        ax=ax,\n",
    "        df=joined.dropna(),\n",
    "        col_name=var,\n",
    "        params=plot_params.get(var, default_params),\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(joined_margolis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(joined_neigh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
